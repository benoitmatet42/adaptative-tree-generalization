{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd23d20a",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "# Spatialization\n",
    "* Using the Orange OD Matrix as a transition matrix to draw destinations for the census equipped with agendas.\n",
    "\n",
    "\n",
    "## Summary\n",
    "* [Loading data](#data)\n",
    "    * [GIS](#gis)\n",
    "    * [transition_matrices](#od)\n",
    "    * [synthetic pop](#synthpop) ([Grouping agendas](#Grouping_agendas))\n",
    "    \n",
    "    \n",
    "* [Drawing](#drawing) \n",
    "    * [utilitary](#utilitary)\n",
    "    * [parameters](#parameters)\n",
    "    * [Parsing transition matrices into dictionnaries](#preproc)\n",
    "    * [Functions to query probas](#proba)\n",
    "    * [Running](#running)\n",
    "    \n",
    "    \n",
    "* [Sanity checks](#sanity)\n",
    "* [Adding empty agendas](#add_empty)\n",
    "* [Exportation & conclusion](#export)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5a6b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import geopandas as gpd\n",
    "import numba\n",
    "from numba import njit, prange\n",
    "from numba_progress import ProgressBar\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.chrono import Chrono\n",
    "\n",
    "with open('config.json', 'r') as config_path:\n",
    "    config = json.load(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc43b0f",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54231aa",
   "metadata": {},
   "source": [
    "<a id='gis'></a>\n",
    "## GIS\n",
    "* Just to get the nearest neighbours for when agents ask for flows that do not exist in the transition matrix\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9282cf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_path = os.path.join(config['outdata_dir']['path'], config['outdata_dir']['gis_map_filename'])\n",
    "iris_commune = gpd.read_file(gis_path)\n",
    "\n",
    "iris_commune = iris_commune.drop(columns=['wkt','geometry', 'is_iris'])\n",
    "\n",
    "for col in iris_commune.columns:\n",
    "    iris_commune[col] = iris_commune[col].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c17077d",
   "metadata": {},
   "source": [
    "<a id='od'></a>\n",
    "## Transition matrices\n",
    "* <font color='red'> **v8h**: Transition matrix is not differentiated by mode</font>\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5aee275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:21:52\tLoading transition matrix from /Users/benoit/Desktop/Pro/210526-fusion/outdata/trans_matrix_by_distbin.csv\n",
      "00:00:20\t2274789 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>o</th>\n",
       "      <th>d</th>\n",
       "      <th>t</th>\n",
       "      <th>vol</th>\n",
       "      <th>proba_d</th>\n",
       "      <th>cart_key</th>\n",
       "      <th>x_o</th>\n",
       "      <th>y_o</th>\n",
       "      <th>geometry</th>\n",
       "      <th>x_d</th>\n",
       "      <th>y_d</th>\n",
       "      <th>centroid_dist</th>\n",
       "      <th>dist_bin_min</th>\n",
       "      <th>dist_bin_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1043</td>\n",
       "      <td>1043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.132230</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.932173e+06</td>\n",
       "      <td>2.538223e+06</td>\n",
       "      <td>POLYGON ((3931567.736276 2535603.293955, 39314...</td>\n",
       "      <td>3.932173e+06</td>\n",
       "      <td>2.538223e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1043</td>\n",
       "      <td>1043</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.813602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.932173e+06</td>\n",
       "      <td>2.538223e+06</td>\n",
       "      <td>POLYGON ((3931567.736276 2535603.293955, 39314...</td>\n",
       "      <td>3.932173e+06</td>\n",
       "      <td>2.538223e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1043</td>\n",
       "      <td>1043</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.833213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.932173e+06</td>\n",
       "      <td>2.538223e+06</td>\n",
       "      <td>POLYGON ((3931567.736276 2535603.293955, 39314...</td>\n",
       "      <td>3.932173e+06</td>\n",
       "      <td>2.538223e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1043</td>\n",
       "      <td>1043</td>\n",
       "      <td>7.0</td>\n",
       "      <td>54.360548</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.932173e+06</td>\n",
       "      <td>2.538223e+06</td>\n",
       "      <td>POLYGON ((3931567.736276 2535603.293955, 39314...</td>\n",
       "      <td>3.932173e+06</td>\n",
       "      <td>2.538223e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1043</td>\n",
       "      <td>1043</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.113536</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.932173e+06</td>\n",
       "      <td>2.538223e+06</td>\n",
       "      <td>POLYGON ((3931567.736276 2535603.293955, 39314...</td>\n",
       "      <td>3.932173e+06</td>\n",
       "      <td>2.538223e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      o     d    t        vol  proba_d  cart_key           x_o           y_o   \n",
       "0  1043  1043  0.0   9.132230      1.0         1  3.932173e+06  2.538223e+06  \\\n",
       "1  1043  1043  2.0   5.813602      1.0         1  3.932173e+06  2.538223e+06   \n",
       "2  1043  1043  5.0  17.833213      1.0         1  3.932173e+06  2.538223e+06   \n",
       "3  1043  1043  7.0  54.360548      1.0         1  3.932173e+06  2.538223e+06   \n",
       "4  1043  1043  8.0  29.113536      1.0         1  3.932173e+06  2.538223e+06   \n",
       "\n",
       "                                            geometry           x_d   \n",
       "0  POLYGON ((3931567.736276 2535603.293955, 39314...  3.932173e+06  \\\n",
       "1  POLYGON ((3931567.736276 2535603.293955, 39314...  3.932173e+06   \n",
       "2  POLYGON ((3931567.736276 2535603.293955, 39314...  3.932173e+06   \n",
       "3  POLYGON ((3931567.736276 2535603.293955, 39314...  3.932173e+06   \n",
       "4  POLYGON ((3931567.736276 2535603.293955, 39314...  3.932173e+06   \n",
       "\n",
       "            y_d  centroid_dist  dist_bin_min  dist_bin_max  \n",
       "0  2.538223e+06            0.0             0         200.0  \n",
       "1  2.538223e+06            0.0             0         200.0  \n",
       "2  2.538223e+06            0.0             0         200.0  \n",
       "3  2.538223e+06            0.0             0         200.0  \n",
       "4  2.538223e+06            0.0             0         200.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_matrix_path = os.path.join(config['outdata_dir']['path'],\n",
    "                                      config['outdata_dir']['transition_matrix_by_dist_filename'])\n",
    "c = Chrono('Loading transition matrix from {}'.format(transition_matrix_path))\n",
    "trans_matrix = pd.read_csv(transition_matrix_path)\n",
    "c.write('{} rows'.format(len(trans_matrix)))\n",
    "trans_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b5af85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 2274789\n",
      "With dense matrices, could be: 3978375\n",
      "meaning we have 1703586 zeros (43%)\n"
     ]
    }
   ],
   "source": [
    "print('Number of parameters: {}'.format(len(trans_matrix)))\n",
    "print('With dense matrices, could be: {}'.format(515*515*15))\n",
    "nb_zeros = 515*515*15 - len(trans_matrix)\n",
    "print('meaning we have {} zeros ({:.0%})'.format(nb_zeros, nb_zeros/(515*515*15)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f6e728",
   "metadata": {},
   "source": [
    "<a id='synthpop'></a>\n",
    "## Synthetic population\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27588fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:22:13\tLoading agents from /Users/benoit/Desktop/Pro/210526-fusion/outdata/synthpop/synthpop_statmatch_rescaleipu.csv\n",
      "00:00:10\t1335786 rows, 1 row per agents\n",
      "00:00:10\tmax_chain_len = 10\n",
      "00:00:10\tWork complete !\n"
     ]
    }
   ],
   "source": [
    "synthpop_path = os.path.join(config['outdata_dir']['path'], config['outdata_dir']['synthpop_rescaled_filename'])\n",
    "\n",
    "c=Chrono('Loading agents from {}'.format(synthpop_path))\n",
    "synthpop = pd.read_csv(synthpop_path)\n",
    "c.tprint('{} rows, 1 row per agents'.format(len(synthpop)))\n",
    "\n",
    "max_chain_len = synthpop['chain_len'].max()\n",
    "c.tprint('max_chain_len = {}'.format(max_chain_len))\n",
    "\n",
    "c.done()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2835b383",
   "metadata": {},
   "source": [
    "<a id='Grouping_agendas'></a>\n",
    "### Grouping agendas\n",
    "* Agendas are considered equivalent if they share the same activity chain and the same home zone.\n",
    "* Note that we could broaden the equivalence because the exact secondary purposes do not impact the spatialisation.\n",
    "* But it doesn't change a lot actually.\n",
    "* <font color='red'> **v8**: agendas that only differ in their transport modes are considered equivalent  </font>\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4295ba0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:22:24\tGrouping agendas...\n",
      "00:00:11\t390221 distinct agendas\n",
      "00:00:11\t283041 agents with empty agendas, we don't spatialise them and they have to be added at the end\n",
      "00:00:11\tWork complete !\n"
     ]
    }
   ],
   "source": [
    "c=Chrono('Grouping agendas...')\n",
    "synthpop['id_agent'] = np.arange(len(synthpop))\n",
    "\n",
    "agenda_cols = ['dep_0_motif'] + ['dep_{}_{}'.format(i, carac) for i in range(1,max_chain_len+1) \n",
    "               for carac in ['motif', 'time']]\n",
    "\n",
    "\n",
    "synthpop_grouped = (synthpop[(synthpop['chain_len']>0) & (synthpop['autonomy']>0)]\n",
    "                    .groupby(agenda_cols+['iris_or_commune'], dropna=False)\n",
    "                    .agg({'chain_len':'first',\n",
    "                          'gender':'count',\n",
    "                          'autonomy':'first',\n",
    "                          'id_agent':list})\n",
    "                    .rename(columns={'gender':'vol'}).reset_index())\n",
    "\n",
    "synthpop_empty_agenda = synthpop.loc[(synthpop['chain_len']==0) | (synthpop['autonomy']==0)].copy()\n",
    "\n",
    "c.write('{} distinct agendas'.format(len(synthpop_grouped)))\n",
    "c.write('{} agents with empty agendas, we don\\'t spatialise them '\n",
    "        'and they have to be added at the end'.format(len(synthpop_empty_agenda)))\n",
    "c.done()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01386c70",
   "metadata": {},
   "source": [
    "## Counting number of meaningully different agendas\n",
    "* All secondary activities are the same\n",
    "* Primary activities that happen only once in the agenda are like a secondary activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eac6a249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 0, 3, 3, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_equiv_mask(purpose_row):\n",
    "    \"\"\"\n",
    "    input : a list of activity purposes\n",
    "    return : primary activities happening only one are counted as secondary. \n",
    "            secondary activities are all counted as 3\n",
    "    \"\"\"\n",
    "    res = purpose_row.copy()\n",
    "    for p in [0,1,2]:\n",
    "        if (purpose_row==p).sum()<=1:\n",
    "            purpose_row[purpose_row==p] = 3\n",
    "    purpose_row[purpose_row>=3] = 3\n",
    "    return purpose_row\n",
    "\n",
    "get_equiv_mask(np.array([0,1,0,2,3,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b309ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dep_0_motif</th>\n",
       "      <th>dep_1_motif</th>\n",
       "      <th>dep_1_time</th>\n",
       "      <th>dep_2_motif</th>\n",
       "      <th>dep_2_time</th>\n",
       "      <th>dep_3_motif</th>\n",
       "      <th>dep_3_time</th>\n",
       "      <th>dep_4_motif</th>\n",
       "      <th>dep_4_time</th>\n",
       "      <th>dep_5_motif</th>\n",
       "      <th>...</th>\n",
       "      <th>dep_6_time</th>\n",
       "      <th>dep_7_motif</th>\n",
       "      <th>dep_7_time</th>\n",
       "      <th>dep_8_motif</th>\n",
       "      <th>dep_8_time</th>\n",
       "      <th>dep_9_motif</th>\n",
       "      <th>dep_9_time</th>\n",
       "      <th>dep_10_motif</th>\n",
       "      <th>dep_10_time</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2817 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dep_0_motif  dep_1_motif  dep_1_time  dep_2_motif  dep_2_time   \n",
       "0             0.0          1.0         2.0          0.0         9.0  \\\n",
       "1             0.0          1.0         2.0          0.0        10.0   \n",
       "2             0.0          1.0         2.0          0.0        10.0   \n",
       "3             0.0          1.0         2.0          0.0        10.0   \n",
       "4             0.0          1.0         2.0          0.0        12.0   \n",
       "...           ...          ...         ...          ...         ...   \n",
       "2812          3.0          3.0        19.0          NaN         NaN   \n",
       "2813          3.0          3.0        20.0          3.0         0.0   \n",
       "2814          3.0          3.0        20.0          3.0        22.0   \n",
       "2815          3.0          3.0        20.0          NaN         NaN   \n",
       "2816          3.0          3.0        22.0          NaN         NaN   \n",
       "\n",
       "      dep_3_motif  dep_3_time  dep_4_motif  dep_4_time  dep_5_motif  ...   \n",
       "0             1.0        14.0          0.0        20.0          NaN  ...  \\\n",
       "1             1.0        12.0          0.0        16.0          NaN  ...   \n",
       "2             1.0        12.0          0.0        19.0          NaN  ...   \n",
       "3             1.0        14.0          0.0        19.0          NaN  ...   \n",
       "4             1.0        16.0          0.0        20.0          NaN  ...   \n",
       "...           ...         ...          ...         ...          ...  ...   \n",
       "2812          NaN         NaN          NaN         NaN          NaN  ...   \n",
       "2813          NaN         NaN          NaN         NaN          NaN  ...   \n",
       "2814          NaN         NaN          NaN         NaN          NaN  ...   \n",
       "2815          NaN         NaN          NaN         NaN          NaN  ...   \n",
       "2816          NaN         NaN          NaN         NaN          NaN  ...   \n",
       "\n",
       "      dep_6_time  dep_7_motif  dep_7_time  dep_8_motif  dep_8_time   \n",
       "0            NaN          NaN         NaN          NaN         NaN  \\\n",
       "1            NaN          NaN         NaN          NaN         NaN   \n",
       "2            NaN          NaN         NaN          NaN         NaN   \n",
       "3            NaN          NaN         NaN          NaN         NaN   \n",
       "4            NaN          NaN         NaN          NaN         NaN   \n",
       "...          ...          ...         ...          ...         ...   \n",
       "2812         NaN          NaN         NaN          NaN         NaN   \n",
       "2813         NaN          NaN         NaN          NaN         NaN   \n",
       "2814         NaN          NaN         NaN          NaN         NaN   \n",
       "2815         NaN          NaN         NaN          NaN         NaN   \n",
       "2816         NaN          NaN         NaN          NaN         NaN   \n",
       "\n",
       "      dep_9_motif  dep_9_time  dep_10_motif  dep_10_time  0  \n",
       "0             NaN         NaN           NaN          NaN  1  \n",
       "1             NaN         NaN           NaN          NaN  1  \n",
       "2             NaN         NaN           NaN          NaN  1  \n",
       "3             NaN         NaN           NaN          NaN  1  \n",
       "4             NaN         NaN           NaN          NaN  1  \n",
       "...           ...         ...           ...          ... ..  \n",
       "2812          NaN         NaN           NaN          NaN  5  \n",
       "2813          NaN         NaN           NaN          NaN  1  \n",
       "2814          NaN         NaN           NaN          NaN  1  \n",
       "2815          NaN         NaN           NaN          NaN  5  \n",
       "2816          NaN         NaN           NaN          NaN  1  \n",
       "\n",
       "[2817 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sgr = synthpop_grouped.groupby(agenda_cols, dropna=False).size().reset_index()\n",
    "\n",
    "purposes = sgr[['dep_0_motif'] + ['dep_{}_motif'.format(i) for i in range(1,max_chain_len+1)]].values\n",
    "for i, row in enumerate(purposes):\n",
    "    purposes[i] = get_equiv_mask(row)\n",
    "\n",
    "sgr[['dep_0_motif'] + ['dep_{}_motif'.format(i) for i in range(1,max_chain_len+1)]] = purposes\n",
    "sgr.groupby(agenda_cols, dropna=False).size().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb1662",
   "metadata": {},
   "source": [
    "<a id='drawing'></a>\n",
    "# Drawing spatialization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e699c",
   "metadata": {},
   "source": [
    "<a id='utilitary'></a>\n",
    "## Utilitary functions\n",
    "* Recoding lots of basic functions so they work with numba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee5dbb0",
   "metadata": {},
   "source": [
    "### SQL-join between two 2-columns arrays\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c704c659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   0., 100.],\n",
       "       [  2.,   0., 200.],\n",
       "       [  4.,   0., 400.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@njit\n",
    "def npjoin(a_keycol, a, b_keycol, b, outer_value):\n",
    "    \"\"\"\n",
    "    a_keycol, b_keycol, a, b : all are np.array\n",
    "    Interpreted as 2 arrays of 2 columns\n",
    "    sql-style outer join np.arrays a and b on columns akey and bkey\n",
    "    assume a is sorted by akey and b by bkey\n",
    "    assume keys do not have repeating values\n",
    "    Outer join but missing keys are not assigned NaN, rather a (small) value\n",
    "    Because we may have no key in common\n",
    "    also it smoothes a bit the impossible flows\n",
    "    return np of 3 columns :\n",
    "        key, aval, bval\n",
    "    \"\"\"\n",
    "    r = np.empty((a.shape[0]+b.shape[0], 3))\n",
    "    ia = 0\n",
    "    ib = 0\n",
    "    ir = 0\n",
    "    while ia<len(a) and ib<len(b):\n",
    "        if a_keycol[ia]<b_keycol[ib]:\n",
    "            r[ir, 0] = a_keycol[ia]\n",
    "            r[ir, 1] = a[ia]\n",
    "            r[ir, 2] = outer_value\n",
    "            ia += 1\n",
    "            ir += 1\n",
    "            \n",
    "        elif a_keycol[ia]>b_keycol[ib]:\n",
    "            r[ir, 0] = b_keycol[ib]\n",
    "            r[ir, 1] = outer_value\n",
    "            r[ir, 2] = b[ib]\n",
    "            ib += 1\n",
    "            ir += 1\n",
    "\n",
    "        else:\n",
    "            r[ir, 0] = a_keycol[ia]\n",
    "            r[ir, 1] = a[ia]\n",
    "            r[ir, 2] = b[ib]\n",
    "            ir += 1\n",
    "            ia += 1\n",
    "            ib += 1\n",
    "    \n",
    "    while ia<len(a):\n",
    "        r[ir, 0] = a_keycol[ia]\n",
    "        r[ir, 1] = a[ia]\n",
    "        r[ir, 2] = outer_value\n",
    "        ia += 1\n",
    "        ir += 1\n",
    "    \n",
    "    while ib<len(b):\n",
    "        r[ir, 0] = b_keycol[ib]\n",
    "        r[ir, 1] = outer_value\n",
    "        r[ir, 2] = b[ib]\n",
    "        ib += 1\n",
    "        ir += 1\n",
    "\n",
    "    return r[:ir]\n",
    "\n",
    "# import timeit\n",
    "# n = 10000\n",
    "# m = int(1.5*n)\n",
    "# akey = np.random.choice(m, n)\n",
    "# sortind = np.argsort(akey)\n",
    "# a = np.arange(n)[sortind]\n",
    "# akey = akey[sortind]\n",
    "# \n",
    "# bkey = np.random.choice(m, n)\n",
    "# sortind = np.argsort(bkey)\n",
    "# b = np.arange(n)[sortind]\n",
    "# bkey = bkey[sortind]\n",
    "# \n",
    "# npjoin(akey, a , bkey, b, 0.01)\n",
    "# %timeit npjoin(akey, a , bkey, b, 0.01)\n",
    "\n",
    "npjoin(np.array([1,3]), \n",
    "       np.array([10,30]),\n",
    "       np.array([1,2,4]), \n",
    "       np.array([100, 200,400]), 0)\n",
    "\n",
    "npjoin(np.zeros(shape=0), \n",
    "       np.zeros(shape=0),\n",
    "       np.array([1,2,4]), \n",
    "       np.array([100, 200,400]), 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97594bf",
   "metadata": {},
   "source": [
    "#### Wrapper for `npjoin` that return output in the same foramt as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fc6954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def join_odz(o_list, proba_o, d_list, proba_d, eps=1e-10):\n",
    "    \"\"\"joining proba of o with proba of d\"\"\"\n",
    "    z_arr = npjoin(o_list, proba_o, d_list, proba_d, eps)\n",
    "    z_list = z_arr[:,0]\n",
    "    \n",
    "    new_probao_col = 1\n",
    "    new_probad_col = 2\n",
    "    proba_z = z_arr[:, new_probao_col] * z_arr[:, new_probad_col]\n",
    "    return z_list, proba_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465dffe3",
   "metadata": {},
   "source": [
    "### tile\n",
    "* re-implement np.tile because it's not managed by numba\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3535bc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom nptile:\n",
      "2.32 µs ± 93.1 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "original nptile:\n",
      "5.52 µs ± 89.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "@njit\n",
    "def nptile(a, n):\n",
    "    \"\"\"\n",
    "    re-implement np.tile because it's not managed by numba\n",
    "    \"\"\"\n",
    "    return a.repeat(n).reshape((-1, n)).T.flatten()\n",
    "\n",
    "nptile(np.array([1,2,3]), 2)\n",
    "\n",
    "print('custom nptile:')\n",
    "%timeit nptile(np.array([1,2,3]), 5)\n",
    "print('original nptile:')\n",
    "%timeit np.tile(np.array([1,2,3]), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e21c3cc",
   "metadata": {},
   "source": [
    "### choice\n",
    "* re-implement np.random.choice because weighting is not managed by numba.\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3885deca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom npchoice:\n",
      "1.37 µs ± 19.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "original np.random.choice:\n",
      "25.2 µs ± 315 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "@njit\n",
    "def npchoice(a, p):\n",
    "    \"\"\"\n",
    "    re-implement np.random.choice because weighting is not managed by numba.\n",
    "    Is 2x faster if we don't have to cumsum here, but for our case it's cleaner to put the cumsum here\n",
    "    and not slower because we never sample twice with the same p\n",
    "    /!\\ Unlike np.choice:\n",
    "        - sample a unique element of a with probability array p\n",
    "    \"\"\"\n",
    "    if len(a)==0:\n",
    "        raise ValueError('given array is empty !')\n",
    "    r = np.random.rand()\n",
    "    return a[np.searchsorted(p.cumsum(), r, side='left')]\n",
    "\n",
    "a = np.arange(500)\n",
    "p = np.random.rand(len(a))\n",
    "p = p/p.sum()\n",
    "npchoice(a, p)\n",
    "print('custom npchoice:')\n",
    "%timeit npchoice(a, p)\n",
    "print('original np.random.choice:')\n",
    "%timeit np.random.choice(a, p=p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1980faa",
   "metadata": {},
   "source": [
    "<a id='parameters'></a>\n",
    "## Spatialisation parameters\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bad28f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nb of iterations to warm MCMC before sampling, w.r.t. autonomy\n",
    "nb_warm_iter_dict = 1000 * np.ones(10, dtype=int)\n",
    "nb_warm_iter_dict[1] = 1\n",
    "nb_warm_iter_dict[2] = 50\n",
    "nb_warm_iter_dict[3] = 200\n",
    "\n",
    "# Nb of iterations we discard between 2 samples of MCMC w.r.t. autonomy\n",
    "nb_cooldown_iter_dict = 1000 * np.ones(10, dtype=int)\n",
    "nb_cooldown_iter_dict[1] = 0\n",
    "nb_cooldown_iter_dict[2] = 10\n",
    "nb_cooldown_iter_dict[3] = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8161840",
   "metadata": {},
   "source": [
    "<a id='preproc'></a>\n",
    "## Preparing df to dicts of arrays\n",
    "* we transform all pd.DataFrame to np.array, \n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d0870e",
   "metadata": {},
   "source": [
    "### making sure we find the right columns\n",
    "* <font color='red'>**v8:** no column for mode </font>\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20521c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#trans_matrix_arr = trans_matrix[['o', 'd', 't', 'proba_d']].values\n",
    "trans_matrix_arr = trans_matrix[['o', 'd', 't', 'vol']].values\n",
    "o_col, d_col, t_col, probad_col = 0, 1, 2, 3\n",
    "\n",
    "#assert (trans_matrix['proba_d'] == trans_matrix_arr[:,probad_col]).all()\n",
    "assert (trans_matrix['t'] == trans_matrix_arr[:,t_col]).all()\n",
    "assert (trans_matrix['d'] == trans_matrix_arr[:,d_col]).all()\n",
    "assert (trans_matrix['o'] == trans_matrix_arr[:,o_col]).all()\n",
    "\n",
    "iris_commune_arr = iris_commune.values\n",
    "z_col, neighbor_0_col = 0, 5\n",
    "assert (iris_commune['iris_or_commune'] == iris_commune_arr[:, z_col]).all()\n",
    "assert (iris_commune['nearest_neighbor_0'] == iris_commune_arr[:, neighbor_0_col]).all()\n",
    "max_neighbor_rank = 20\n",
    "\n",
    "motif_col_names = ['dep_{}_motif'.format(i) for i in range(max_chain_len+1)]\n",
    "motif_cols = np.arange(len(motif_col_names), dtype=int)\n",
    "time_col_names = ['dep_{}_time'.format(i) for i in range(1, max_chain_len+1)]\n",
    "time_cols = np.arange(len(motif_col_names), len(motif_col_names)+len(time_col_names), dtype=int)\n",
    "\n",
    "chain_len_col = len(motif_cols) + len(time_cols)\n",
    "home_col = chain_len_col + 1\n",
    "vol_col = home_col + 1\n",
    "autonomy_col = vol_col + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecdb611",
   "metadata": {},
   "source": [
    "### ztr_to_i\n",
    "* we slice our arrays into numba dicts but tuples are not accepted as keys in numba dicts\n",
    "\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d72f8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def zt_to_i(z,t):\n",
    "    \"\"\"tuples (z,t) are not accepted as keys in numba dicts\"\"\"\n",
    "    return z*1000+t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448a6319",
   "metadata": {},
   "source": [
    "### `create_trans_matrix_d_dict_numba`\n",
    "* transforming the transition matrix to dicts:\n",
    "* `d_list_dict`: dict of (origin, timestep, transport mode): list of each possible destination\n",
    "* `proba_d_dict`: dict of (origin, timestep, transport mode): list of probas for each possible destination\n",
    "* <font color='red'>**v8:** no mode</font>\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec950775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 536/536 [00:03<00:00, 136.66it/s]\n"
     ]
    }
   ],
   "source": [
    "timesteps = trans_matrix['t'].unique()\n",
    "from numba.typed import Dict\n",
    "from numba.core import types\n",
    "\n",
    "float_array = types.float64[:]\n",
    "float_type = types.float64\n",
    "\n",
    "def create_trans_matrix_d_dict_numba(trans_matrix_arr):\n",
    "    \n",
    "    # Make dictionary\n",
    "    d_list_dict = Dict.empty(\n",
    "        key_type=float_type,\n",
    "        value_type=float_array,\n",
    "    )\n",
    "    proba_d_dict = Dict.empty(\n",
    "    key_type=float_type,\n",
    "    value_type=float_array\n",
    "    )\n",
    "    \n",
    "    for o in tqdm(np.unique(trans_matrix_arr[:,o_col])):\n",
    "        trans_matrix_sub_o = trans_matrix_arr[(trans_matrix_arr[:, o_col]==o)]\n",
    "        for t in timesteps:\n",
    "            trans_matrix_sub = trans_matrix_sub_o[(trans_matrix_sub_o[:, t_col]==t)].astype(np.float64)\n",
    "\n",
    "            k = zt_to_i(o,t)\n",
    "            sort_ind = np.argsort(trans_matrix_sub[:,d_col])\n",
    "            \n",
    "            d_list_dict[k] = trans_matrix_sub[sort_ind, d_col]\n",
    "            proba_d_dict[k] = trans_matrix_sub[sort_ind, probad_col]\n",
    "        \n",
    "\n",
    "    return d_list_dict, proba_d_dict\n",
    "\n",
    "\n",
    "d_list_dict, proba_d_dict = create_trans_matrix_d_dict_numba(trans_matrix_arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68ac1a",
   "metadata": {},
   "source": [
    "### `create_trans_matrix_o_dict_numba`\n",
    "* transforming the transition matrix to dicts:\n",
    "* `o_list_dict`: dict of (destination, timestep, transport mode): list of each possible origin\n",
    "* `proba_o_dict`: dict of (destination, timestep, transport mode): list of probas for each possible origin\n",
    "* <font color='red'>**v8:** no mode</font>\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23ce871f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 536/536 [00:03<00:00, 150.78it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_trans_matrix_o_dict_numba(trans_matrix_arr):\n",
    "    # numba-ficiation of this does makes the notebook stop responding\n",
    "    \n",
    "    # Make dictionary\n",
    "    o_list_dict = Dict.empty(\n",
    "        key_type=float_type,\n",
    "        value_type=float_array,\n",
    "    )\n",
    "    proba_o_dict = Dict.empty(\n",
    "    key_type=float_type,\n",
    "    value_type=float_array\n",
    "    )\n",
    "    \n",
    "    for d in tqdm(np.unique(trans_matrix_arr[:,d_col])):\n",
    "        trans_matrix_sub_d = trans_matrix_arr[(trans_matrix_arr[:, d_col]==d)]\n",
    "        for t in timesteps:\n",
    "            trans_matrix_sub = trans_matrix_sub_d[(trans_matrix_sub_d[:, t_col]==t)]\n",
    "\n",
    "            k = zt_to_i(d,t)\n",
    "            sort_ind = np.argsort(trans_matrix_sub[:,o_col])\n",
    "            \n",
    "            o_list_dict[k] = trans_matrix_sub[sort_ind, o_col]\n",
    "            proba_o_dict[k] = trans_matrix_sub[sort_ind, probad_col]\n",
    "        \n",
    "    return o_list_dict, proba_o_dict\n",
    "\n",
    "\n",
    "o_list_dict, proba_o_dict = create_trans_matrix_o_dict_numba(trans_matrix_arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7989a64",
   "metadata": {},
   "source": [
    "<a id='proba'></a>\n",
    "## Functions to query probas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c49ee87",
   "metadata": {},
   "source": [
    "### `get_proba_o` and `get_proba_d`\n",
    "* <font color='red'>**v8:** no mode</font>\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc0ff4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@njit\n",
    "def get_proba_o(o_list_dict, proba_o_dict, d, t):\n",
    "    \"\"\"\n",
    "    return proba of each o given d, t\n",
    "    d: destination\n",
    "    t: timestep\n",
    "    \n",
    "    If no origin exist for this dt, look into the nearest neighbor of d\n",
    "    iteratively as long as we didn't exhaust the list of nearest neighbors.\n",
    "    \"\"\"\n",
    "    key = zt_to_i(d,t)\n",
    "    o_list = o_list_dict.get(key)\n",
    "    \n",
    "    # getting the transitions from nearest zone instead\n",
    "    if o_list is None or len(o_list)==0:\n",
    "        neighbor_col = neighbor_0_col\n",
    "        z_row = iris_commune_arr[iris_commune_arr[:, z_col]==d]\n",
    "        while (neighbor_col<z_row.shape[1]) and ((o_list is None) or (len(o_list)==0)):\n",
    "            if neighbor_col==z_row.shape[1]:\n",
    "                return np.empty(shape=0), np.empty(shape=0)\n",
    "\n",
    "            nn = z_row[:, neighbor_col].item()\n",
    "            key = zt_to_i(nn,t)\n",
    "            o_list = o_list_dict.get(key)\n",
    "            neighbor_col += 1\n",
    "            \n",
    "    proba_o = proba_o_dict[key]\n",
    "    return o_list, proba_o\n",
    "\n",
    "@njit\n",
    "def get_proba_d(d_list_dict, proba_d_dict, o, t):\n",
    "    \"\"\"\n",
    "    return proba of each d given o, t, m\n",
    "    o: origin\n",
    "    t: timestep\n",
    "    \n",
    "    If no destination exist for this otm, look into the nearest neighbor of o\n",
    "    iteratively as long as we didn't exhaust the list of nearest neighbors.\n",
    "    \"\"\"\n",
    "    key = zt_to_i(o,t)\n",
    "    d_list = d_list_dict.get(key)\n",
    "    \n",
    "    # getting the transitions from nearest zone instead\n",
    "    if d_list is None or len(d_list)==0:\n",
    "        neighbor_col = neighbor_0_col\n",
    "        z_row = iris_commune_arr[iris_commune_arr[:, z_col]==o]\n",
    "        while (neighbor_col<z_row.shape[1]) and ((d_list is None) or (len(d_list)==0)):\n",
    "            if neighbor_col==z_row.shape[1]:\n",
    "                return np.empty(shape=0), np.empty(shape=0)\n",
    "            nn = z_row[:, neighbor_col].item()\n",
    "            key = zt_to_i(nn,t)\n",
    "            d_list = d_list_dict.get(key)\n",
    "            neighbor_col += 1\n",
    "\n",
    "    proba_d = proba_d_dict[key]\n",
    "    return d_list, proba_d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f60ae7",
   "metadata": {},
   "source": [
    "### `get_proba_z`\n",
    "* is proportional to `proba_o * proba_d`\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12f5c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_proba_z(row, locations, o_list_dict, proba_o_dict, \n",
    "                           d_list_dict, proba_d_dict, \n",
    "                dim, time_cols):\n",
    "    time_col = time_cols[dim]\n",
    "    time_prev_col = time_cols[dim-1]\n",
    "    \n",
    "    if dim==0:  # first place may not be home\n",
    "        z_list, proba_z = get_proba_o(o_list_dict, proba_o_dict,\n",
    "                              locations[dim+1],  # destination\n",
    "                              row[time_col], # curr timestep\n",
    "                             )\n",
    "\n",
    "    elif dim==len(locations)-1:  # last place may not be home\n",
    "        z_list, proba_z = get_proba_d(d_list_dict, proba_d_dict,\n",
    "                                  locations[dim-1], # origin\n",
    "                                  row[time_prev_col], # prev timestep\n",
    "                                 )\n",
    "                \n",
    "    else:\n",
    "        o_list, proba_o = get_proba_o(o_list_dict, proba_o_dict,\n",
    "                              locations[dim+1],  # destination\n",
    "                              row[time_col], # curr timestep\n",
    "                             )\n",
    "        \n",
    "        d_list, proba_d = get_proba_d(d_list_dict, proba_d_dict,\n",
    "                              locations[dim-1], # origin\n",
    "                              row[time_prev_col], # prev timestep\n",
    "                             )\n",
    "\n",
    "        z_list, proba_z = join_odz(o_list, proba_o, d_list, proba_d, eps=1e-10)\n",
    "\n",
    "    return z_list, proba_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f300eb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity purposes: [0. 2. 2. 3. 4. 3. 0.]\n",
      "link sets : [0 1 1 2 3 4 0]\n",
      "activities appearing more than once: [0 1]\n"
     ]
    }
   ],
   "source": [
    "@njit\n",
    "def get_link_mask(purpose_row):\n",
    "    \"\"\"\n",
    "    input : a list of activity purposes\n",
    "    return : a list of ids for linksets. \n",
    "        Activities belonging to the same linkset are expected to have the same location.\n",
    "    \"\"\"\n",
    "    linkset_ids = np.zeros(shape=len(purpose_row), dtype=np.int32)\n",
    "    max_state_id = 0\n",
    "    purpose_visited = -np.ones(len(purpose_row))  # stash list\n",
    "    purpose_to_id = -np.ones(len(purpose_row))  # dict list\n",
    "    for i, p in enumerate(purpose_row.astype(np.int32)):\n",
    "        if p in purpose_visited:\n",
    "            linkset_ids[i] = purpose_to_id[p]\n",
    "        else:\n",
    "            if (p>=0) and (p<=2):  # home, work or study\n",
    "                purpose_visited[max_state_id] = p\n",
    "                purpose_to_id[p] = max_state_id\n",
    "                linkset_ids[i] = max_state_id\n",
    "                max_state_id += 1\n",
    "            else:\n",
    "                linkset_ids[i] = max_state_id\n",
    "                max_state_id += 1\n",
    "    return linkset_ids\n",
    "\n",
    "@njit\n",
    "def get_non_singleton_linksets(link_mask):\n",
    "    return np.array([i for i in np.unique(link_mask) if (link_mask==i).sum()>1])\n",
    "\n",
    "\n",
    "purposes_example = np.array([0.,2.,2.,3.,4.,3.,0.])\n",
    "print('activity purposes: {}'.format(purposes_example))\n",
    "lm = get_link_mask(purposes_example)\n",
    "print('link sets : {}'.format(lm))\n",
    "print('activities appearing more than once: {}'.format(get_non_singleton_linksets(lm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eec2d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@njit\n",
    "def get_proba_z_linked(row, locations, o_list_dict, proba_o_dict, \n",
    "                           d_list_dict, proba_d_dict, \n",
    "                            dim, time_cols, chain_len):\n",
    "    \"\"\"\n",
    "    get_proba_z but handles the linked states.\n",
    "    /!\\ Assumes linked states NEVER follow each others.\n",
    "    \"\"\"\n",
    "    link_mask = get_link_mask(row[:chain_len])\n",
    "    non_singleton_linksets = get_non_singleton_linksets(link_mask)\n",
    "    \n",
    "    \n",
    "    if link_mask[dim] in non_singleton_linksets:\n",
    "        #dict (neighboring linkset):(id of each possible zone for current linkset)\n",
    "        list_linkset_dict = Dict.empty(key_type=types.int32, value_type=float_array)\n",
    "\n",
    "        #dict (neighboring linkset):(proba of each possible zone for current linkset)\n",
    "        proba_linkset_dict = Dict.empty(key_type=types.int32, value_type=float_array)\n",
    "        \n",
    "        # number of factors in common with each linkset\n",
    "        exponant_linksets = np.zeros(link_mask.max()+1)\n",
    "\n",
    "        for dim_linked in np.where(row[:chain_len]==row[dim])[0]:\n",
    "            if dim_linked<chain_len-1:\n",
    "                o_list_linked, proba_o_linked = get_proba_o(o_list_dict, proba_o_dict, \n",
    "                                                            locations[dim_linked+1],\n",
    "                                                            row[time_cols[dim_linked]])\n",
    "\n",
    "                next_purpose = link_mask[dim_linked+1]\n",
    "                exponant_linksets[next_purpose] += 1\n",
    "                if next_purpose in proba_linkset_dict:\n",
    "                    res_list, proba_res = join_odz(list_linkset_dict[next_purpose], \n",
    "                                                   proba_linkset_dict[next_purpose],\n",
    "                                                   o_list_linked, \n",
    "                                                   proba_o_linked)\n",
    "                    list_linkset_dict[next_purpose] = res_list\n",
    "                    proba_linkset_dict[next_purpose] = proba_res\n",
    "                else:\n",
    "                    list_linkset_dict[next_purpose] = o_list_linked\n",
    "                    proba_linkset_dict[next_purpose] = proba_o_linked\n",
    "                    \n",
    "            if dim_linked>0:\n",
    "                d_list_linked, proba_d_linked = get_proba_d(d_list_dict, proba_d_dict, \n",
    "                                                            locations[dim_linked-1], \n",
    "                                                            row[time_cols[dim_linked-1]])\n",
    "\n",
    "                prev_purpose = link_mask[dim_linked-1]\n",
    "                exponant_linksets[prev_purpose] += 1\n",
    "                if prev_purpose in proba_linkset_dict:\n",
    "                    res_list, proba_res = join_odz(list_linkset_dict[prev_purpose], \n",
    "                                                   proba_linkset_dict[prev_purpose],\n",
    "                                                   o_list_linked, \n",
    "                                                   proba_o_linked)\n",
    "                    list_linkset_dict[prev_purpose] = res_list\n",
    "                    proba_linkset_dict[prev_purpose] = proba_res\n",
    "                else:\n",
    "                    list_linkset_dict[prev_purpose] = d_list_linked\n",
    "                    proba_linkset_dict[prev_purpose] = proba_d_linked\n",
    "\n",
    "                    \n",
    "            # count double transitions that we see in factor graphs\n",
    "            # (a bit optional, doesn't change much the result anyway)\n",
    "            if (dim_linked+2<len(link_mask)) and (link_mask[dim_linked+2]==link_mask[dim_linked]):\n",
    "                if dim_linked>0 and (link_mask[dim_linked-1]==link_mask[dim_linked+1]):\n",
    "                    exponant_linksets[next_purpose] += 1\n",
    "                    res_list, proba_res = join_odz(list_linkset_dict[next_purpose], \n",
    "                                                   proba_linkset_dict[next_purpose],\n",
    "                                                   o_list_linked, \n",
    "                                                   proba_o_linked)\n",
    "                    list_linkset_dict[next_purpose] = res_list\n",
    "                    proba_linkset_dict[next_purpose] = proba_res\n",
    "                    \n",
    "            if (dim_linked-2>=0) and (link_mask[dim_linked-2]==link_mask[dim_linked]):\n",
    "                if dim_linked+1<len(link_mask) and (link_mask[dim_linked-1]==link_mask[dim_linked+1]):\n",
    "                    exponant_linksets[prev_purpose] += 1\n",
    "                    res_list, proba_res = join_odz(list_linkset_dict[prev_purpose], \n",
    "                                                   proba_linkset_dict[prev_purpose],\n",
    "                                                   o_list_linked, \n",
    "                                                   proba_o_linked)\n",
    "                    list_linkset_dict[prev_purpose] = res_list\n",
    "                    proba_linkset_dict[prev_purpose] = proba_res\n",
    "            #####\n",
    "            \n",
    "        # Applying root corrections and multiplying all proba laws\n",
    "        z_list, proba_z = np.zeros(shape=0), np.zeros(shape=0)\n",
    "        for i in range(len(exponant_linksets)):\n",
    "            if exponant_linksets[i]>0:\n",
    "                proba_linkset_dict[i] = np.power(proba_linkset_dict[i], 1/exponant_linksets[i])\n",
    "                z_list, proba_z = join_odz(list_linkset_dict[i], proba_linkset_dict[i], z_list, proba_z)\n",
    "\n",
    "    else: # linkset is singleton\n",
    "        z_list, proba_z = get_proba_z(row, locations, o_list_dict, proba_o_dict, \n",
    "                                                      d_list_dict, proba_d_dict, \n",
    "                                                      dim, time_cols)\n",
    "\n",
    "        # if prev and next dims are in the same linkset:\n",
    "        if dim>0 and dim<chain_len-1 and (row[dim-1]==row[dim+1]) and (row[dim-1]>=0) and (row[dim-1]<=2):\n",
    "            proba_z = np.sqrt(proba_z)\n",
    "\n",
    "    return z_list, proba_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eb1c2d",
   "metadata": {},
   "source": [
    "<a id='running'></a>\n",
    "## Running spatialisation in itself\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81ec303a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6154f6185a147c2b6c655fd05359ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                | 0/390221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4m/96kct6fd1vl7ty8sc_mpj7kw0000gp/T/ipykernel_26036/1775577505.py:88: NumbaTypeSafetyWarning: \u001b[1m\u001b[1m\u001b[1munsafe cast from int64 to int32. Precision may be lost.\u001b[0m\u001b[0m\u001b[0m\n",
      "  proba_linkset_dict[i] = np.power(proba_linkset_dict[i], 1/exponant_linksets[i])\n"
     ]
    }
   ],
   "source": [
    "int_type = types.int8\n",
    "int_array = types.int8[:]\n",
    "\n",
    "#@njit(parallel=True)\n",
    "def spatialize(synthpop_grouped_sub_arr, nb_warm_iter_dict, nb_cooldown_iter_dict, \n",
    "              o_list_dict, proba_o_dict, d_list_dict, proba_d_dict,\n",
    "              progress_proxy):\n",
    "    locations_sampled = np.zeros(shape=(int(synthpop_grouped_sub_arr[:, vol_col].sum()), max_chain_len+1))\n",
    "    cum_vols = synthpop_grouped_sub_arr[:, vol_col].cumsum()\n",
    "    \n",
    "    for irow in prange(len(synthpop_grouped_sub_arr)):\n",
    "        row = synthpop_grouped_sub_arr[irow]\n",
    "        \n",
    "        # Getting max autonomy of segments of the agenda\n",
    "        autonomy = int(row[autonomy_col])\n",
    "        nb_iter = int(nb_warm_iter_dict[autonomy]+row[vol_col]*(nb_cooldown_iter_dict[autonomy] + 1))\n",
    "    \n",
    "        chain_len = int(row[chain_len_col]+1)\n",
    "\n",
    "        locations = np.random.choice(a=iris_commune_arr[:, z_col], size=(chain_len))\n",
    "        \n",
    "        # first cols are about motive\n",
    "        home_mask = (row[:chain_len]==0)\n",
    "\n",
    "        # Something smart to not have to browse the entire agenda each time we want to fetch linked states:\n",
    "        #link_dict = Dict.empty(key_type=int_type, value_type=int_array)\n",
    "        #for i, motive in enumerate(row[:chain_len]):\n",
    "        #    if i not in link_dict:\n",
    "        #        if motive==1 or motive==2:\n",
    "        #            link_dict[i] = np.where(row[:chain_len]==motive)[0].astype(np.int8)\n",
    "        #        elif motive != 0:\n",
    "        #            link_dict[i] = i\n",
    "        \n",
    "        locations[home_mask] = row[home_col]\n",
    "        draw_mask = ~home_mask\n",
    "\n",
    "        draw_indices = draw_mask.nonzero()[0] # indices we will have to draw in MCMC\n",
    "        \n",
    "        # # pre-fetching phase, not implemented\n",
    "        # for i in draw_indices:\n",
    "        #     ...\n",
    "        \n",
    "        # Sampling each dimension in order, this way we make sure all segments are drawn \n",
    "        # One iteration is drawing all states that have to be drawn, in order.\n",
    "        # We could take a random order but then we wouldn't be sure that all states have been drawn\n",
    "        # in long segments for chains that have a long segment and a short one.\n",
    "        dim_to_draw = nptile(draw_indices, nb_iter)\n",
    "\n",
    "        # i_sample: index of where we save the trajectory we draw in locations_sampled.\n",
    "        # Each trajectory can concern several agents, so we may have to sample it more than once.\n",
    "        # So each trajectory has an assigned slot for the first sample, and the following samples\n",
    "        # are saved in the follow rows.\n",
    "        if irow==0:\n",
    "            i_sample=0\n",
    "        else:\n",
    "            i_sample = int(cum_vols[irow-1])\n",
    "        \n",
    "        for i, dim in enumerate(dim_to_draw):\n",
    "            z_list, proba_z = get_proba_z_linked(row, locations, o_list_dict, proba_o_dict, \n",
    "                                                  d_list_dict, proba_d_dict, \n",
    "                                                  dim, time_cols, chain_len)\n",
    "            proba_z = proba_z/proba_z.sum()\n",
    "\n",
    "            tirage = npchoice(z_list, proba_z)\n",
    "            locations[dim] = tirage\n",
    "            \n",
    "            ## Sampling once as soon as we finished warmup, and once each time the cooldown is finished\n",
    "            if ((i>=nb_warm_iter_dict[autonomy]*len(draw_indices)) and \n",
    "             (i-len(draw_indices)*nb_warm_iter_dict[autonomy]) % (len(draw_indices)*(nb_cooldown_iter_dict[autonomy] + 1)) == 0):\n",
    "                locations_sampled[i_sample, :chain_len] = locations\n",
    "                i_sample+=1\n",
    "                \n",
    "        progress_proxy.update(1)\n",
    "    return locations_sampled\n",
    "\n",
    "# 00:15:00\n",
    "synthpop_grouped_sub = synthpop_grouped\n",
    "synthpop_grouped_sub_arr = synthpop_grouped_sub[motif_col_names + \n",
    "                                                time_col_names+\n",
    "                                                ['chain_len', 'iris_or_commune', 'vol', 'autonomy']].values\n",
    "with ProgressBar(total=len(synthpop_grouped_sub_arr)) as progress:\n",
    "    locations_sampled = spatialize(synthpop_grouped_sub_arr, nb_warm_iter_dict, nb_cooldown_iter_dict,\n",
    "                                   o_list_dict, proba_o_dict, d_list_dict, proba_d_dict,\n",
    "                                   progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a0a79f",
   "metadata": {},
   "source": [
    "<a id='sanity'></a>\n",
    "# Sanity checks\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab8e1df",
   "metadata": {},
   "source": [
    "* No trajectory has failed to be attributed something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01947728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of trajectories that are only 0's: 0\n"
     ]
    }
   ],
   "source": [
    "print('Nb of trajectories that are only 0\\'s: {}'.format(np.all(locations_sampled==0,axis=1).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c96477",
   "metadata": {},
   "source": [
    "* Right amount of chains of each len. \n",
    "* **Note:** Offset of 1 in chain_len is explained because `locations_sampled` also has a column for the location 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e77a4660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of chain_len in synthpop:\n",
      "\n",
      "chain_len\n",
      "0     283041\n",
      "1      21920\n",
      "2     555982\n",
      "3     105410\n",
      "4     260108\n",
      "5      55532\n",
      "6      40492\n",
      "7       9446\n",
      "8       2962\n",
      "9        493\n",
      "10       400\n",
      "dtype: int64\n",
      "\n",
      "Distribution of len of location chains sampled:\n",
      "nb_locations\n",
      "2      21920\n",
      "3     555982\n",
      "4     105410\n",
      "5     260108\n",
      "6      55532\n",
      "7      40492\n",
      "8       9446\n",
      "9       2962\n",
      "10       493\n",
      "11       400\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Distribution of chain_len in synthpop:\\n')\n",
    "print(synthpop.groupby('chain_len').size())\n",
    "print('\\nDistribution of len of location chains sampled:')\n",
    "chain_len_locations = np.sum((locations_sampled!=0),axis=1)\n",
    "print(pd.DataFrame({'nb_locations':chain_len_locations}).groupby('nb_locations').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2f3d87",
   "metadata": {},
   "source": [
    "* But the order is wrong !\n",
    "* Order seems consistent with the order of `synthpop_grouped`\n",
    "* So it's the groupby that messed up our order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bfb9fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of consistent chain len between synthpop_grouped and location chains sampled:\n",
      "100%\n"
     ]
    }
   ],
   "source": [
    "print('Fraction of consistent chain len between synthpop_grouped and location chains sampled:')\n",
    "print('{:.0f}%'.format(100*(np.repeat(synthpop_grouped['chain_len'], \n",
    "                                      synthpop_grouped['vol'])==chain_len_locations-1).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d148e7",
   "metadata": {},
   "source": [
    "* Joining agendas with an ad hoc key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce9b1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 00:00:02\n",
    "\n",
    "id_agent = (synthpop_grouped['id_agent'].explode()).values\n",
    "\n",
    "location_df = pd.DataFrame(locations_sampled, columns=['dep_{}_zone'.format(i) for i in range(max_chain_len+1)])\n",
    "location_df['id_agent'] = id_agent\n",
    "\n",
    "synthpop_sampled = (synthpop\n",
    "                    .drop(columns=['dep_{}_zone'.format(i) for i in range(max_chain_len+1)])\n",
    "                    .merge(location_df, on='id_agent'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3367560a",
   "metadata": {},
   "source": [
    "* Check that we have no doublon or disappearing agent in the merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "faf9e4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of synthpop: \t 1335786\n",
      "len of location chains:  1052745\n",
      "len of synthpop merged:  1052745\n"
     ]
    }
   ],
   "source": [
    "print('len of synthpop: \\t {}'.format(len(synthpop)))\n",
    "print('len of location chains:  {}'.format(len(locations_sampled)))\n",
    "print('len of synthpop merged:  {}'.format(len(synthpop_sampled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab9d947",
   "metadata": {},
   "source": [
    "* Static trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59774eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.54% of agents don't move at all\n"
     ]
    }
   ],
   "source": [
    "zone_cols = ['dep_{}_zone'.format(i) for i in range(max_chain_len+1)]\n",
    "synthpop[zone_cols] = synthpop[zone_cols].fillna(0)\n",
    "synthpop_locations_sampled = synthpop[zone_cols].values\n",
    "moved = (synthpop_locations_sampled[:,1:] != synthpop_locations_sampled[:,:-1])\n",
    "padding = synthpop_locations_sampled[:,1:]==0\n",
    "static_traj = (~(moved & ~padding)).all(axis=1)\n",
    "print('{:.2f}% of agents don\\'t move at all'.format(100*static_traj.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ece4e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(synthpop_sampled['chain_len']==0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b16205",
   "metadata": {},
   "source": [
    "<a id='add_empty'></a>\n",
    "# Adding empty agendas\n",
    "* They have been removed from the dataset at the beginning\n",
    "* Now put them back\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f718c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_chain_len+1):\n",
    "    synthpop_empty_agenda['dep_{}_zone'.format(i)] = 0\n",
    "synthpop_sampled = pd.concat([synthpop_sampled, synthpop_empty_agenda])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d41b8d",
   "metadata": {},
   "source": [
    "<a id='export'></a>\n",
    "# Export\n",
    "* [back to summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d50dd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 18:13:18.646673\n",
      "/Users/benoit/Desktop/Pro/210526-fusion/outdata/synthpop/synthpop_statmatch_rescaleipu_spatializev8h2.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iris_or_commune</th>\n",
       "      <th>gender</th>\n",
       "      <th>has_car</th>\n",
       "      <th>occupation</th>\n",
       "      <th>age</th>\n",
       "      <th>home_status</th>\n",
       "      <th>main_transport_work</th>\n",
       "      <th>id_agenda</th>\n",
       "      <th>dep_0_motif</th>\n",
       "      <th>outsider</th>\n",
       "      <th>...</th>\n",
       "      <th>dep_1_zone</th>\n",
       "      <th>dep_2_zone</th>\n",
       "      <th>dep_3_zone</th>\n",
       "      <th>dep_4_zone</th>\n",
       "      <th>dep_5_zone</th>\n",
       "      <th>dep_6_zone</th>\n",
       "      <th>dep_7_zone</th>\n",
       "      <th>dep_8_zone</th>\n",
       "      <th>dep_9_zone</th>\n",
       "      <th>dep_10_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>690270102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1320021221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>691000101.0</td>\n",
       "      <td>690270102.0</td>\n",
       "      <td>692020401.0</td>\n",
       "      <td>69116.0</td>\n",
       "      <td>690270102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1320021221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>692870101.0</td>\n",
       "      <td>69288.0</td>\n",
       "      <td>69289.0</td>\n",
       "      <td>692870102.0</td>\n",
       "      <td>69288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69298</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1320021221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>692590602.0</td>\n",
       "      <td>69298.0</td>\n",
       "      <td>69289.0</td>\n",
       "      <td>69289.0</td>\n",
       "      <td>69298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>692661301</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1320021221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>693850201.0</td>\n",
       "      <td>692661301.0</td>\n",
       "      <td>693830301.0</td>\n",
       "      <td>693830301.0</td>\n",
       "      <td>692661301.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>690890301</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1320021221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>692440201.0</td>\n",
       "      <td>690890301.0</td>\n",
       "      <td>69044.0</td>\n",
       "      <td>69044.0</td>\n",
       "      <td>690890301.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iris_or_commune  gender  has_car  occupation  age  home_status   \n",
       "0        690270102       0        1           8    3            0  \\\n",
       "1            69288       0        1           6    1            0   \n",
       "2            69298       0        1           6    2            0   \n",
       "3        692661301       0        1           7    0            0   \n",
       "4        690890301       0        1           5    2            0   \n",
       "\n",
       "   main_transport_work   id_agenda  dep_0_motif  outsider  ...   dep_1_zone   \n",
       "0                   -1  1320021221          0.0       0.0  ...  691000101.0  \\\n",
       "1                    2  1320021221          0.0       0.0  ...  692870101.0   \n",
       "2                    5  1320021221          0.0       0.0  ...  692590602.0   \n",
       "3                   -1  1320021221          0.0       0.0  ...  693850201.0   \n",
       "4                   -1  1320021221          0.0       0.0  ...  692440201.0   \n",
       "\n",
       "    dep_2_zone   dep_3_zone   dep_4_zone   dep_5_zone  dep_6_zone  dep_7_zone   \n",
       "0  690270102.0  692020401.0      69116.0  690270102.0         0.0         0.0  \\\n",
       "1      69288.0      69289.0  692870102.0      69288.0         0.0         0.0   \n",
       "2      69298.0      69289.0      69289.0      69298.0         0.0         0.0   \n",
       "3  692661301.0  693830301.0  693830301.0  692661301.0         0.0         0.0   \n",
       "4  690890301.0      69044.0      69044.0  690890301.0         0.0         0.0   \n",
       "\n",
       "   dep_8_zone  dep_9_zone  dep_10_zone  \n",
       "0         0.0         0.0          0.0  \n",
       "1         0.0         0.0          0.0  \n",
       "2         0.0         0.0          0.0  \n",
       "3         0.0         0.0          0.0  \n",
       "4         0.0         0.0          0.0  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outpath = synthpop_path[:-4] + '_spatializev8h2.csv'\n",
    "synthpop_sampled.to_csv(outpath, index=False)\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "print(outpath)\n",
    "synthpop_sampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c51480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
